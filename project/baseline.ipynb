{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":"import numpy as np\nimport operator\nfrom ours_eval import csls_knn_10_score, evaluation\nfrom icp import ICPTrainer\nimport multiprocessing\nimport matplotlib.pyplot as plt\nimport time\nimport utils\nimport params\nimport sklearn.cluster\nfrom sklearn.decomposition import PCA"},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":"def sub_icp(src_W, tgt_W, n_icp_runs):\n    def run_icp(s0, i):\n        np.random.seed(s0 + i)\n        icp = ICPTrainer(src_W.copy(), tgt_W.copy(), True, params.n_pca)\n        t0 = time.time()\n        indices_x, indices_y, rec, bb = icp.train_icp(params.icp_init_epochs)\n        dt = time.time() - t0\n        print(\"%d: Rec %f BB %d Time: %f\" % (i, rec, bb, dt))\n        return indices_x, indices_y, rec, bb\n    data = np.zeros((n_icp_runs, 2)) #100, 2\n\n    best_idx_x = None\n    best_idx_y = None\n\n    min_rec = 1e8\n    s0 = np.random.randint(50000)\n    results = []\n    if params.n_processes == 1:\n        for i in range( n_icp_runs):\n            results += [run_icp(s0, i)]\n    else:\n        pool = multiprocessing.Pool(processes=params.n_processes)\n        for result in tqdm.tqdm(pool.imap_unordered(run_icp, range(n_icp_runs)), total=n_icp_runs):\n            results += [result]\n        pool.close()\n\n    min_rec = 1e8\n    min_bb = None\n    for i, result in enumerate(results):\n        indices_x, indices_y, rec, bb = result\n        data[i, 0] = rec\n        data[i, 1] = bb\n        if rec < min_rec:\n            best_idx_x = indices_x\n            best_idx_y = indices_y\n            min_rec = rec\n            min_bb = bb\n\n\n    idx = np.argmin(data[:, 0], 0)\n    print(\"Init - Achieved: Rec %f BB %d\" % (data[idx, 0], data[idx, 1]))\n    icp_train = ICPTrainer(src_W, tgt_W, False, src_W.shape[0])\n    _, _, rec, bb = icp_train.train_icp(params.icp_train_epochs, True, best_idx_x, best_idx_y)\n    print(\"Training - Achieved: Rec %f BB %d\" % (rec, bb))\n\n    TX = icp_train.icp.TX\n    TY = icp_train.icp.TY\n    return TX, TY"},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Loaded 200000 pre-trained word embeddings.\nLoaded 200000 pre-trained word embeddings.\ndata/en-es.5000-6500.txt\nFound 2975 pairs of words in the dictionary (1500 unique). 0 other pairs contained at least one unknown word (0 in lang1, 0 in lang2)\ndata/es-en.5000-6500.txt\nFound 2416 pairs of words in the dictionary (1500 unique). 0 other pairs contained at least one unknown word (0 in lang1, 0 in lang2)\n"}],"source":"src_id2word, src_word2id, src_embeddings = utils.read_txt_embeddings('data/wiki.%s.vec' % params.src_lang, params.n_eval_ex, False) #n_eval_ex = 200000\ntgt_id2word, tgt_word2id, tgt_embeddings = utils.read_txt_embeddings('data/wiki.%s.vec' % params.tgt_lang, params.n_eval_ex, False)\nsrc_normed = src_embeddings / np.linalg.norm(src_embeddings, ord=2, axis=1, keepdims=True)\ntgt_normed = tgt_embeddings / np.linalg.norm(tgt_embeddings, ord=2, axis=1, keepdims=True)\ncross_dict_src2tgt = utils.load_dictionary('data/%s-%s.5000-6500.txt' % (params.src_lang, params.tgt_lang), src_word2id, tgt_word2id)\ncross_dict_tgt2src = utils.load_dictionary('data/%s-%s.5000-6500.txt' % (params.tgt_lang, params.src_lang), tgt_word2id, src_word2id)"},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"(5000, 300)\n"}],"source":"src_full = np.load(\"data/%s_%d.npy\" % (params.src_lang, params.n_init_ex)) # 5000, 5000 english\ntgt_full = np.load(\"data/%s_%d.npy\" % (params.tgt_lang, params.n_init_ex)) # 300, 5000 es\nprint(src_full.shape)"},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"0: Rec 6.945307 BB 348 Time: 13.663379\n1: Rec 6.707236 BB 337 Time: 13.698650\n2: Rec 6.947372 BB 332 Time: 13.657169\n3: Rec 6.951586 BB 354 Time: 13.569556\n4: Rec 6.565661 BB 365 Time: 13.584978\nInit - Achieved: Rec 6.565661 BB 365\nTraining - Achieved: Rec 10.149690 BB 793\n"}],"source":"# original -baseline\n#TX, TY = sub_icp(src_full[:5000,:].T, tgt_full[:5000,:].T)\nTX, TY = sub_icp(src_full[:2500,:].T, tgt_full[:2500,:].T, 20)"},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":"from utils import get_nn_avg_dist\ndef csls_knn_10_score(emb_trans, emb_tgt, dico):\n    emb_trans = emb_trans / np.linalg.norm(emb_trans, ord=2, axis=1, keepdims=True)\n    emb_tgt = emb_tgt / np.linalg.norm(emb_tgt, ord=2, axis=1, keepdims=True)\n    emb_trans = emb_trans.astype('float32')\n    emb_tgt = emb_tgt.astype('float32')\n    # I use csls_knn_10 directly\n    average_dist1 = get_nn_avg_dist(emb = emb_tgt, query = emb_trans, knn = 10) #(200000,)\n    average_dist2 = get_nn_avg_dist(emb = emb_trans, query = emb_tgt, knn = 10) #(200000,)\n    \n    query = emb_trans[dico[:, 0]] # dico[:, 0] is from source Domain, # dico[:, 1] is from target domain\n    scores = 2 * query.dot(emb_tgt.T) #2975*200000\n    scores -= average_dist1[dico[:, 0]][:, None] # right hand side: 2975, 1\n    scores -= average_dist2[None,:] # right hand side: 1, 200000\n    \n    return scores"},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"1500 source words -   - Precision at k = 1: 0.066667\n1500 source words -   - Precision at k = 5: 0.066667\n1500 source words -   - Precision at k = 10: 0.333333\n"},{"data":{"text/plain":"[('precision_at_1', 0.06666666666666667),\n ('precision_at_5', 0.06666666666666667),\n ('precision_at_10', 0.33333333333333337)]"},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":"# original - baseline\nTranslatedX = src_embeddings.dot(np.transpose(TX))\nscores = csls_knn_10_score(emb_trans=TranslatedX, emb_tgt=tgt_embeddings, dico=cross_dict_src2tgt)\nevaluation(scores, cross_dict_src2tgt)"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":""}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}